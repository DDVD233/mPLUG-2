alpha: 0.4
bert_config: configs/config_bert_large_text.json
concat_last_layer: true
clip_name: "ViT-L-14"
distill: true
embed_dim: 256
eos: '[SEP]'
add_ocr: true
add_object: true

optimizer: {lr1: 2e-5, lr2: 2e-6, opt: adamW, weight_decay: 0.02, betas: [0.9, 0.999]}
# queue_size: 65536
schedular: {cooldown_epochs: 0, decay_rate: 1, epochs: 10, lr: 2e-5, min_lr: 1e-06,
  sched: cosine_step, warmup_epochs: 200, warmup_lr: 1e-06}

# Data
read_local_data: true
train_file: ['datasets/moma_qa/train.json']
test_file: ['datasets/moma_qa/test.json']
answer_list: 'datasets/moma_qa/full_ans2label.json'
answer_list_vocab: 'datasets/moma_qa/vocab.json'
answer_list_vocab_1000: 'datasets/moma_qa/vocab1000.json'
label_file: 'datasets/moma_qa/test.json'
video_root: "moma/videos/"
sgg: false

image_res: 224
model_num_frames: 16
test_num_frames: 16

vision_width: 1024
use_checkpoint: true
k_test: 128

batch_size_train: 1
batch_size_test: 1
num_workers: 24